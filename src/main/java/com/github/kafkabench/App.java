/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package com.github.kafkabench;

import static com.google.common.math.Quantiles.percentiles;

import com.google.common.util.concurrent.RateLimiter;
import java.time.Duration;
import java.time.Instant;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Random;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.BytesSerializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.apache.kafka.common.utils.Bytes;

public class App {

  public static void main(String[] args) throws Exception {
    new App().run();
  }

  void run() throws Exception {
    Config config = new Config();
    Reporter reporter = new Reporter(config);
    List<ProducerThread> producers = new ArrayList<>();

    System.out.println("Config: " + config);
    System.out.println("Producer: " + config.getProducerProperties());

    ExecutorService executor = Executors.newFixedThreadPool(config.getConcurrency());
    for (int i = 0; i < config.getConcurrency(); i++) {
      ProducerThread producer = new ProducerThread(config, reporter);
      producers.add(producer);
      executor.execute(producer);
    }
    long updates = config.getRuntime().toMillis() / config.getStatusUpdateInterval().toMillis();
    for (int i = 0; i < Math.max(1, updates); i++) {
      Thread.sleep(Math.min(
          config.getRuntime().toMillis(),
          config.getStatusUpdateInterval().toMillis()));
      reporter.printStatus();
    }

    System.out.println("Shutting down...");
    producers.forEach(ProducerThread::shutdown);
    executor.shutdown();
    executor.awaitTermination(1000, TimeUnit.MILLISECONDS);

    reporter.print();
  }

  static class Config {

    private final Duration runtime;
    private final int concurrency;
    private final int throughput;
    private final Duration statusUpdateInterval;
    private final String topic;
    private final int recordSize;
    private final String key;
    private int partition;
    private byte[] payload;


    Config() {
      this.throughput = 2000;
      this.runtime = Duration.ofSeconds(10);
      this.concurrency = 8;
      this.statusUpdateInterval = Duration.ofSeconds(2);
      this.partition = 0;

      this.topic = "test";
      this.key = "key";
      this.recordSize = 50;
      this.payload = new byte[recordSize];
      Random rand = new Random();
      rand.nextBytes(payload);
    }

    String getTopic() {
      return topic;
    }

    Duration getRuntime() {
      return runtime;
    }

    int getConcurrency() {
      return concurrency;
    }

    RateLimiter getRateLimiter() {
      return RateLimiter.create(throughput * 1.0 / concurrency);
    }

    int getPartition() {
      return partition;
    }

    Duration getStatusUpdateInterval() {
      return statusUpdateInterval;
    }

    String getKey() {
      return key;
    }

    byte[] getPayload() {
      return payload;
    }

    Properties getProducerProperties() {
      Properties props = new Properties();
      props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
      return props;
    }

    @Override
    public String toString() {
      return "Config{" +
          "runtime=" + runtime +
          ", concurrency=" + concurrency +
          ", throughput=" + throughput +
          ", topic=" + topic +
          ", partition=" + partition +
          ", recordSize=" + recordSize +
          ", statusUpdateInterval=" + statusUpdateInterval +
          '}';
    }
  }

  static class ProducerThread implements Runnable {

    private final Config config;
    private final Reporter reporter;
    private boolean running;

    ProducerThread(Config config, Reporter reporter) {
      this.config = config;
      this.reporter = reporter;
    }

    @Override
    public void run() {
      Timer timer = new Timer();
      KafkaProducer<String, Bytes> producer = buildProducer();
      RateLimiter rateLimiter = config.getRateLimiter();

      ProducerRecord<String, Bytes> record = new ProducerRecord<>(
          config.getTopic(),
          config.getPartition(),
          config.getKey(),
          Bytes.wrap(config.getPayload()));

      running = true;

      try {
        // don't measure metadata fetch overhead
        producer.send(record).get();
        while (running) {
          timer.start();
          rateLimiter.acquire();
          producer.send(record).get();
          reporter.report(timer.stop());
        }
      } catch (InterruptedException | ExecutionException e) {
        e.printStackTrace();
      }
    }

    KafkaProducer<String, Bytes> buildProducer() {
      Properties props = config.getProducerProperties();
      props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
      props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, BytesSerializer.class.getName());
      return new KafkaProducer<>(props);
    }

    void shutdown() {
      this.running = false;
    }
  }

  static class Timer {

    private Instant start;

    void start() {
      this.start = Instant.now();
    }

    Duration stop() {
      return Duration.between(start, Instant.now());
    }
  }

  static class Reporter {

    private final List<Duration> timings = new ArrayList<>();
    private final Config config;

    Reporter(Config config) {
      this.config = config;
    }

    void printStatus() {
      System.out.println("Sent " + timings.size() + " records");
    }

    void print() {
      List<Long> nanos = timings.stream().map(Duration::toNanos).collect(Collectors.toList());

      long total = nanos.stream().reduce(0L, Long::sum);
      double avg = total * 1.0 / timings.size();
      long throughput = timings.size() / config.getRuntime().getSeconds();
      Map<Integer, Double> percentiles = percentiles().indexes(50, 90, 95, 99).compute(nanos);

      System.out.println(String.format("Runtime: %d seconds", config.getRuntime().getSeconds()));
      System.out.println(String.format("Records: %d", timings.size()));
      System.out.println(String.format("Throughput: %d records/s", throughput));
      System.out.println("Min: " + formatTiming(Collections.min(nanos)));
      System.out.println("Max: " + formatTiming(Collections.max(nanos)));
      System.out.println("Avg: " + formatTiming(avg));
      System.out.println("p50: " + formatTiming(percentiles.get(50)));
      System.out.println("p90: " + formatTiming(percentiles.get(90)));
      System.out.println("p95: " + formatTiming(percentiles.get(95)));
      System.out.println("p99: " + formatTiming(percentiles.get(99)));
    }

    private String formatTiming(long nano) {
      return String.format("%.2f ms", nano / 1_000_000.0);
    }

    private String formatTiming(double nano) {
      return String.format("%.2f ms", nano / 1_000_000.0);
    }

    synchronized void report(Duration timing) {
      timings.add(timing);
    }
  }
}
